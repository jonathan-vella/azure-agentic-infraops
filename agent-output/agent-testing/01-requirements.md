# Step 1: Requirements - Agent Testing & Validation Plan

> Generated by @requirements agent | 2026-01-22

## Project Overview

| Field                   | Value                                                                   |
| ----------------------- | ----------------------------------------------------------------------- |
| **Project Name**        | Agent Testing & Validation Framework                                    |
| **Project Type**        | Quality Assurance / Test Automation                                     |
| **Timeline**            | 4-6 weeks for initial implementation                                    |
| **Primary Stakeholder** | Platform Engineering Team / SI Partners                                 |
| **Business Context**    | Ensure all 9 custom agents in Agentic InfraOps produce reliable outputs |

### Background

The Agentic InfraOps workflow uses 9 custom GitHub Copilot agents that work together
to deliver Azure infrastructure from requirements through deployment and operations.
These agents require comprehensive testing and validation to ensure:

1. **Functional correctness** — Each agent produces expected outputs
2. **Integration validation** — Agents work together in the 7-step workflow
3. **Quality assurance** — Outputs meet documentation and code standards
4. **Regression prevention** — Changes don't break existing functionality
5. **Automation readiness** — Tests can run in CI/CD pipelines

## Functional Requirements

### Core Capabilities

The testing framework must provide:

1. **Automated test execution** — Run tests without manual intervention
2. **Template compliance validation** — Verify H2 heading structure and order
3. **Code quality checks** — Validate Bicep, Python, PowerShell, and Markdown
4. **Golden file comparison** — Detect regressions against baseline outputs
5. **Azure integration testing** — Validate deployments with what-if analysis
6. **CI/CD integration** — Run tests on PR, merge, and scheduled triggers
7. **Detailed reporting** — Provide actionable pass/fail results with remediation

### Agent Inventory

| Step | Agent          | Purpose                            | Primary Input            | Primary Output                  | Test Priority |
| ---- | -------------- | ---------------------------------- | ------------------------ | ------------------------------- | ------------- |
| 1    | `requirements` | NFR and requirements gathering     | User description         | `01-requirements.md`            | **High**      |
| 2    | `architect`    | WAF assessment with cost estimates | `01-requirements.md`     | `02-architecture-assessment.md` | **Critical**  |
| 3a   | `diagram`      | Python architecture diagrams       | Architecture assessment  | `03-des-diagram.py/.png`        | **Medium**    |
| 3b   | `adr`          | Architecture Decision Records      | Architect decisions      | `03-des-adr-*.md`               | **Medium**    |
| 4    | `bicep-plan`   | Implementation planning            | Architecture assessment  | `04-implementation-plan.md`     | **Critical**  |
| 5    | `bicep-code`   | Bicep template generation          | Implementation plan      | `infra/bicep/{project}/`        | **Critical**  |
| 6    | `deploy`       | Azure deployment execution         | Bicep templates          | `06-deployment-summary.md`      | **High**      |
| 7    | `docs`         | Workload documentation             | All prior artifacts      | `07-*.md` (5+ files)            | **Medium**    |
| —    | `diagnose`     | Resource health assessment         | Azure resource reference | Diagnostic reports              | **Low**       |

### Test Categories

| Category                      | Description                                       | Automation Level |
| ----------------------------- | ------------------------------------------------- | ---------------- |
| **Functional Testing**        | Each agent produces expected outputs in isolation | 100% automated   |
| **Integration Testing**       | Agents work together in 7-step workflow           | 95% automated    |
| **Code Quality Testing**      | Generated artifacts pass linting and validation   | 100% automated   |
| **Azure Integration Testing** | Agents interact correctly with Azure APIs         | 90% automated    |
| **Regression Testing**        | Changes don't break existing functionality        | 100% automated   |
| **Performance Testing**       | Agents complete within acceptable timeframes      | 100% automated   |
| **Documentation Validation**  | Generated docs are complete and professional      | 80% automated    |

### Integrations

| System                 | Integration Type | Purpose                                 |
| ---------------------- | ---------------- | --------------------------------------- |
| GitHub Actions         | CI/CD pipeline   | Automated test execution on PR/merge    |
| Azure Resource Graph   | Query API        | Policy discovery testing for bicep-plan |
| Azure Pricing MCP      | MCP server       | Cost estimate validation for architect  |
| Azure AppLens          | Diagnostic API   | Health check testing for diagnose agent |
| Azure Resource Manager | Deployment API   | What-if and deployment validation       |

### Data Types

| Data Category       | Sensitivity | Estimated Volume               |
| ------------------- | ----------- | ------------------------------ |
| Test prompts        | Low         | 50-100 per agent               |
| Golden file outputs | Low         | 500KB-2MB per scenario         |
| Azure credentials   | High        | Service principal for test sub |
| Test results/logs   | Low         | 10-50MB per test run           |

## Non-Functional Requirements (NFRs)

### Availability & Reliability

| Metric  | Target | Justification                                                 |
| ------- | ------ | ------------------------------------------------------------- |
| **SLA** | 99%    | Test infrastructure should be available for CI/CD runs        |
| **RTO** | 1 hour | Restore test capability within 1 hour if infrastructure fails |
| **RPO** | 24 hrs | Test results can be regenerated; no critical data loss        |

### Performance

| Metric                       | Target   | Justification                       |
| ---------------------------- | -------- | ----------------------------------- |
| Full test suite execution    | < 30 min | Fast feedback for PR reviews        |
| Single agent functional test | < 5 min  | Quick validation during development |
| Template compliance check    | < 10 sec | Near-instant feedback               |
| Bicep build/lint             | < 30 sec | Fast validation of generated code   |

### Scalability

| Metric                     | Current | Projected (12 months) |
| -------------------------- | ------- | --------------------- |
| Number of agents           | 9       | 12-15                 |
| Test scenarios             | 5       | 10-15                 |
| Test cases per agent       | 10-20   | 30-50                 |
| Concurrent test executions | 1       | 3-5                   |

## Compliance & Security Requirements

### Regulatory Frameworks

- [ ] HIPAA
- [ ] PCI-DSS
- [ ] GDPR
- [ ] SOC 2
- [ ] ISO 27001
- [x] None — Testing framework has no regulatory requirements

### Data Residency

| Field                | Value                                            |
| -------------------- | ------------------------------------------------ |
| **Primary Region**   | `swedencentral` (same as production deployments) |
| **Data Sovereignty** | EU preferred for test Azure subscriptions        |
| **Cross-region**     | Not required — test resources are ephemeral      |

### Authentication & Authorization

| Field                 | Value                                                        |
| --------------------- | ------------------------------------------------------------ |
| **Identity Provider** | Azure AD (Microsoft Entra ID)                                |
| **MFA Requirement**   | Required for human access, not for service principals        |
| **RBAC Model**        | Contributor on test resource groups, Reader on subscriptions |

### Network Security

- [ ] Private endpoints required
- [ ] VNet integration required
- [x] Public endpoints acceptable (test resources only)
- [ ] WAF required

> **Note**: Test resources use public endpoints for simplicity. Production
> deployments validated by agents use full security controls.

## Budget

| Field               | Value                                          |
| ------------------- | ---------------------------------------------- |
| **Monthly Budget**  | ~$50-100 (test Azure resources)                |
| **Annual Budget**   | ~$600-1200                                     |
| **Hard/Soft Limit** | Soft — can negotiate for comprehensive testing |

> **Note**: Primary costs are Azure test resources (ephemeral deployments).
> CI/CD compute uses GitHub Actions included minutes.

### Cost Optimization Priorities

- [x] Minimize compute costs — Use cheapest SKUs for test resources
- [x] Prefer consumption-based pricing — Serverless where possible
- [ ] Reserved instances acceptable
- [x] Spot instances acceptable — For non-critical test workloads
- [x] Auto-cleanup — Delete test resources after validation

## Operational Requirements

### Monitoring & Alerting

| Requirement          | Configuration                                         |
| -------------------- | ----------------------------------------------------- |
| **Logging**          | GitHub Actions logs, Azure Monitor for deployed tests |
| **Alert Recipients** | Platform engineering team                             |
| **Dashboard Needs**  | Test pass/fail rates, execution times, cost tracking  |
| **Retention**        | 30 days for logs, 90 days for metrics                 |

### Support & Maintenance

| Field                  | Value                                         |
| ---------------------- | --------------------------------------------- |
| **Support Hours**      | Business hours (Mon-Fri, 9am-5pm CET)         |
| **On-call**            | Not required — tests can wait until next day  |
| **Maintenance Window** | Weekends — update test fixtures and baselines |

### Backup & Disaster Recovery

| Component             | Backup Frequency   | Retention  |
| --------------------- | ------------------ | ---------- |
| Golden file baselines | Git (every commit) | Indefinite |
| Test configurations   | Git (every commit) | Indefinite |
| Test results/logs     | Not backed up      | 30 days    |

> **Note**: All test configurations are version-controlled in Git.
> No additional backup infrastructure required.

## Regional Preferences

| Field                  | Value                | Notes                         |
| ---------------------- | -------------------- | ----------------------------- |
| **Primary Region**     | `swedencentral`      | Matches production defaults   |
| **Failover Region**    | `germanywestcentral` | For regional outage scenarios |
| **Availability Zones** | Not required         | Test resources don't need HA  |

---

## Test Scenarios

The following scenarios cover diverse infrastructure types for comprehensive validation:

### Scenario 1: Simple Static Web App (Smoke Test)

| Field          | Value                                   |
| -------------- | --------------------------------------- |
| **Purpose**    | Fast smoke test for agent functionality |
| **Resources**  | Azure Static Web Apps only              |
| **Complexity** | Low                                     |
| **Run Time**   | < 5 minutes                             |
| **Trigger**    | Every PR, every merge                   |

### Scenario 2: API with Database

| Field          | Value                                      |
| -------------- | ------------------------------------------ |
| **Purpose**    | Test common web application pattern        |
| **Resources**  | App Service, Azure SQL Database, Key Vault |
| **Complexity** | Medium                                     |
| **Run Time**   | < 15 minutes                               |
| **Trigger**    | Nightly, major changes                     |

### Scenario 3: Microservices Architecture

| Field          | Value                                           |
| -------------- | ----------------------------------------------- |
| **Purpose**    | Test complex multi-resource deployments         |
| **Resources**  | Container Apps, Service Bus, Key Vault, Storage |
| **Complexity** | High                                            |
| **Run Time**   | < 25 minutes                                    |
| **Trigger**    | Weekly, agent changes                           |

### Scenario 4: Mission-Critical E-commerce

| Field          | Value                                                |
| -------------- | ---------------------------------------------------- |
| **Purpose**    | Test HA, DR, and compliance requirements             |
| **Resources**  | Zone-redundant App Service, SQL with geo-replication |
| **Complexity** | High                                                 |
| **Run Time**   | < 30 minutes                                         |
| **Trigger**    | Weekly, major releases                               |

### Scenario 5: Data Platform

| Field          | Value                                             |
| -------------- | ------------------------------------------------- |
| **Purpose**    | Test data-focused infrastructure patterns         |
| **Resources**  | Storage Account, Data Factory, Synapse (optional) |
| **Complexity** | Medium                                            |
| **Run Time**   | < 20 minutes                                      |
| **Trigger**    | Weekly, data agent changes                        |

---

## Test Case Specifications

### Functional Tests (Per Agent)

#### requirements Agent Tests

| Test Case ID | Description                | Input                      | Expected Outcome                          |
| ------------ | -------------------------- | -------------------------- | ----------------------------------------- |
| REQ-001      | Basic requirements capture | Simple web app description | Valid `01-requirements.md` created        |
| REQ-002      | Template H2 compliance     | Any valid input            | All required H2 sections present in order |
| REQ-003      | NFR completeness           | Any valid input            | SLA, RTO, RPO, budget captured            |
| REQ-004      | Regional defaults applied  | No region specified        | `swedencentral` used as default           |
| REQ-005      | Minimal input handling     | "Web app" only             | Agent asks clarifying questions           |

#### architect Agent Tests

| Test Case ID | Description              | Input              | Expected Outcome                       |
| ------------ | ------------------------ | ------------------ | -------------------------------------- |
| ARC-001      | WAF pillar assessment    | Valid requirements | All 5 WAF pillars scored (1-10)        |
| ARC-002      | Cost estimate generation | Valid requirements | `03-des-cost-estimate.md` created      |
| ARC-003      | Service recommendations  | Valid requirements | SKU recommendations with justification |
| ARC-004      | Template H2 compliance   | Any valid input    | Required H2 sections present in order  |
| ARC-005      | MCP integration          | Valid requirements | Azure Pricing MCP called for costs     |

#### bicep-plan Agent Tests

| Test Case ID | Description                      | Input                     | Expected Outcome                         |
| ------------ | -------------------------------- | ------------------------- | ---------------------------------------- |
| BPL-001      | Resource inventory generation    | Valid architecture        | Complete resource list with dependencies |
| BPL-002      | Module structure planning        | Valid architecture        | Module tree with correct hierarchy       |
| BPL-003      | Governance constraints discovery | Azure subscription access | `04-governance-constraints.json` created |
| BPL-004      | AVM version specification        | Any input                 | Specific AVM versions referenced         |
| BPL-005      | Template H2 compliance           | Any valid input           | Required H2 sections present in order    |

#### bicep-code Agent Tests

| Test Case ID | Description               | Input                     | Expected Outcome                                |
| ------------ | ------------------------- | ------------------------- | ----------------------------------------------- |
| BIC-001      | Bicep syntax validation   | Valid implementation plan | `bicep build` succeeds                          |
| BIC-002      | Bicep linting             | Valid implementation plan | `bicep lint` passes with no errors              |
| BIC-003      | CAF naming conventions    | Any input                 | Resources follow `{type}-{name}-{env}-{region}` |
| BIC-004      | Required tags present     | Any input                 | Environment, ManagedBy, Project, Owner tags     |
| BIC-005      | Security defaults applied | Any input                 | TLS 1.2, HTTPS-only, no public blob access      |
| BIC-006      | Unique suffix generation  | Any input                 | `uniqueString()` used for global names          |
| BIC-007      | Module structure          | Any input                 | main.bicep + modules/ folder structure          |

#### deploy Agent Tests

| Test Case ID | Description                   | Input                 | Expected Outcome                      |
| ------------ | ----------------------------- | --------------------- | ------------------------------------- |
| DEP-001      | What-if analysis              | Valid Bicep templates | What-if completes without errors      |
| DEP-002      | Deployment summary generation | Successful deployment | `06-deployment-summary.md` created    |
| DEP-003      | Resource ID capture           | Successful deployment | All resource IDs listed in summary    |
| DEP-004      | Endpoint URL capture          | App/web deployments   | Public endpoints documented           |
| DEP-005      | Template H2 compliance        | Any valid input       | Required H2 sections present in order |

#### diagram Agent Tests

| Test Case ID | Description              | Input                       | Expected Outcome                    |
| ------------ | ------------------------ | --------------------------- | ----------------------------------- |
| DIA-001      | Python syntax validation | Valid architecture          | Python code executes without errors |
| DIA-002      | Diagrams library imports | Any input                   | Uses `diagrams.azure.*` imports     |
| DIA-003      | PNG generation           | Valid Python diagram        | PNG file created successfully       |
| DIA-004      | Cluster structure        | Multi-resource architecture | Logical grouping with clusters      |
| DIA-005      | Filename convention      | Design phase                | `03-des-diagram.py` naming used     |

#### adr Agent Tests

| Test Case ID | Description                | Input                 | Expected Outcome                     |
| ------------ | -------------------------- | --------------------- | ------------------------------------ |
| ADR-001      | Template compliance        | Architecture decision | ADR template structure followed      |
| ADR-002      | Status field present       | Any input             | Status: Proposed/Accepted/Deprecated |
| ADR-003      | Alternatives documented    | Any input             | At least 2 alternatives listed       |
| ADR-004      | Numbered naming convention | Any input             | `03-des-adr-NNNN-*.md` format        |
| ADR-005      | CAF/WAF alignment          | Any input             | References relevant CAF/WAF guidance |

#### docs Agent Tests

| Test Case ID | Description                     | Input                     | Expected Outcome                          |
| ------------ | ------------------------------- | ------------------------- | ----------------------------------------- |
| DOC-001      | All required files generated    | Complete workflow outputs | 5+ documentation files created            |
| DOC-002      | Design document completeness    | Valid inputs              | `07-design-document.md` complete          |
| DOC-003      | Operations runbook completeness | Valid inputs              | `07-operations-runbook.md` complete       |
| DOC-004      | Cost estimate accuracy          | Valid inputs              | `07-ab-cost-estimate.md` with real prices |
| DOC-005      | Resource inventory accuracy     | Valid inputs              | `07-resource-inventory.md` matches deploy |
| DOC-006      | Markdown quality                | Any output                | Passes markdownlint                       |

#### diagnose Agent Tests

| Test Case ID | Description             | Input                | Expected Outcome                         |
| ------------ | ----------------------- | -------------------- | ---------------------------------------- |
| DGN-001      | Approval-first behavior | Resource reference   | Waits for user approval before execution |
| DGN-002      | AppLens integration     | Valid Azure resource | Queries AppLens successfully             |
| DGN-003      | Health recommendations  | Unhealthy resource   | Actionable recommendations provided      |

### Integration Tests (Workflow Hand-offs)

| Test Case ID | Description                 | Agents Involved          | Validation Criteria                       |
| ------------ | --------------------------- | ------------------------ | ----------------------------------------- |
| INT-001      | Requirements → Architect    | requirements → architect | Architect consumes requirements correctly |
| INT-002      | Architect → Bicep Plan      | architect → bicep-plan   | Plan references architecture decisions    |
| INT-003      | Bicep Plan → Bicep Code     | bicep-plan → bicep-code  | Code implements all planned resources     |
| INT-004      | Bicep Code → Deploy         | bicep-code → deploy      | Deployment uses generated templates       |
| INT-005      | Deploy → Docs               | deploy → docs            | Docs reflect actual deployed resources    |
| INT-006      | Full E2E Workflow           | All 7 steps              | Complete workflow executes successfully   |
| INT-007      | Artifact naming consistency | All agents               | Project name consistent across all files  |

### Code Quality Tests

| Test Case ID | Description           | Tool                              | Pass Criteria                    |
| ------------ | --------------------- | --------------------------------- | -------------------------------- |
| QUA-001      | Bicep build           | `bicep build`                     | Exit code 0, no errors           |
| QUA-002      | Bicep lint            | `bicep lint`                      | No errors, warnings acceptable   |
| QUA-003      | Markdown lint         | `markdownlint-cli2`               | No errors                        |
| QUA-004      | Markdown links        | `markdown-link-check`             | All links resolve                |
| QUA-005      | Python syntax         | `python -m py_compile`            | Valid Python syntax              |
| QUA-006      | PowerShell lint       | `PSScriptAnalyzer`                | No errors, warnings acceptable   |
| QUA-007      | Template H2 structure | `validate-artifact-templates.mjs` | All H2 sections in correct order |

---

## Automation Strategy

### Test Framework Architecture

```
test/
├── functional/              # Per-agent isolation tests
│   ├── requirements/
│   ├── architect/
│   ├── bicep-plan/
│   ├── bicep-code/
│   ├── deploy/
│   ├── diagram/
│   ├── adr/
│   ├── docs/
│   └── diagnose/
├── integration/             # Cross-agent workflow tests
│   ├── handoffs/
│   └── e2e/
├── quality/                 # Code quality validation
│   ├── bicep/
│   ├── markdown/
│   ├── python/
│   └── powershell/
├── azure/                   # Live Azure integration
│   ├── what-if/
│   ├── deploy/
│   └── cleanup/
├── fixtures/                # Test data
│   ├── inputs/              # Sample prompts per scenario
│   ├── golden/              # Expected outputs for regression
│   └── edge-cases/          # Malformed/minimal inputs
└── lib/                     # Shared test utilities
    ├── Test-AgentOutput.ps1
    ├── Compare-GoldenFile.ps1
    └── Invoke-AgentTest.ps1
```

### CI/CD Integration

```yaml
# .github/workflows/test-agents.yml
name: Agent Testing Suite

on:
  pull_request:
    paths:
      - ".github/agents/**"
      - ".github/templates/**"
      - "scripts/**"
  push:
    branches: [main]
  schedule:
    - cron: "0 2 * * *" # Nightly at 2 AM UTC
  workflow_dispatch: # Manual trigger

jobs:
  functional-tests:
    # Per-agent isolation tests

  integration-tests:
    # Cross-agent workflow tests
    needs: functional-tests

  quality-tests:
    # Code quality validation (parallel)

  azure-tests:
    # Live Azure integration (requires approval)
    needs: [functional-tests, integration-tests]
    environment: azure-test
```

### Test Execution Commands

| Command                           | Purpose                      |
| --------------------------------- | ---------------------------- |
| `npm run test:agents`             | Run all agent tests          |
| `npm run test:agents:functional`  | Run functional tests only    |
| `npm run test:agents:integration` | Run integration tests only   |
| `npm run test:agents:quality`     | Run quality validation only  |
| `npm run test:agents:azure`       | Run Azure integration tests  |
| `npm run test:agents:regression`  | Compare against golden files |

---

## Success Metrics

| Metric                   | Target   | Measurement Method                         |
| ------------------------ | -------- | ------------------------------------------ |
| **Test Coverage**        | 100%     | All 9 agents have functional tests         |
| **Pass Rate**            | ≥ 95%    | Tests pass consistently                    |
| **Execution Time**       | < 30 min | Full suite completes within limit          |
| **Automation Level**     | ≥ 90%    | Tests run without manual intervention      |
| **Regression Detection** | < 1 day  | Issues caught within 1 day of introduction |
| **CI/CD Integration**    | 100%     | Tests run on every PR and merge            |
| **Documentation**        | Complete | Test plan and results documented           |
| **False Positive Rate**  | < 5%     | Minimal flaky tests                        |

---

## Implementation Roadmap

### Phase 1: Foundation (Week 1-2)

- [ ] Set up test directory structure
- [ ] Create test utility library (`Test-AgentOutput.ps1`, etc.)
- [ ] Implement template compliance tests (extend existing validation)
- [ ] Create sample inputs for 5 test scenarios
- [ ] Set up CI/CD workflow skeleton

### Phase 2: Functional Tests (Week 2-3)

- [ ] Implement requirements agent tests
- [ ] Implement architect agent tests
- [ ] Implement bicep-plan agent tests
- [ ] Implement bicep-code agent tests
- [ ] Create golden file baselines for regression

### Phase 3: Integration & Quality (Week 3-4)

- [ ] Implement workflow hand-off tests
- [ ] Implement full E2E workflow test
- [ ] Integrate Bicep build/lint validation
- [ ] Integrate markdown linting
- [ ] Integrate Python/PowerShell validation

### Phase 4: Azure Integration (Week 4-5)

- [ ] Set up test Azure subscription with policies
- [ ] Implement what-if analysis tests
- [ ] Implement ephemeral deployment tests
- [ ] Create auto-cleanup scripts
- [ ] Test rate limit and permission handling

### Phase 5: Refinement (Week 5-6)

- [ ] Add remaining agent tests (deploy, docs, diagram, adr, diagnose)
- [ ] Performance baseline establishment
- [ ] Documentation of test procedures
- [ ] Training for team on running tests
- [ ] Final review and sign-off

---

## Risk Mitigation

| Risk                          | Impact | Mitigation Strategy                                     |
| ----------------------------- | ------ | ------------------------------------------------------- |
| **Azure costs exceed budget** | Medium | Use cheapest SKUs, auto-cleanup after tests             |
| **Rate limits on Azure APIs** | Medium | Implement exponential backoff, cache responses          |
| **Flaky tests**               | High   | Retry logic, clear pass/fail criteria                   |
| **Agent behavior changes**    | Medium | Golden files updated with explicit approval             |
| **Test environment drift**    | Low    | Use dev container for consistent environment            |
| **Permission issues**         | Medium | Document required RBAC roles, test with least privilege |

---

## Clarifying Questions — Resolved

### 1. Azure Test Subscription

**Decision**: Use current subscription with ephemeral test resource groups.

| Field               | Value                                       |
| ------------------- | ------------------------------------------- |
| **Subscription**    | `noalz`                                     |
| **Subscription ID** | `00858ffc-dded-4f0f-8bbf-e17fff0d47d9`      |
| **Tenant ID**       | `2d04cb4c-999b-4e60-a3a7-e8993edc768b`      |
| **Test RG Pattern** | `rg-agent-test-{scenario}-{timestamp}`      |
| **Auto-cleanup**    | Delete RG after test completion (max 2 hrs) |

### 2. Golden File Approval Process

**Decision**: User approves with automation assistance.

**Recommended Approach — Automated Golden File Management:**

1. **Diff Generation**: CI automatically generates side-by-side diffs when
   golden files change
2. **PR Comment Bot**: GitHub Action posts diff summary as PR comment with:
   - Files changed count
   - Semantic diff (ignore timestamps, UUIDs)
   - "Approve golden update" checkbox
3. **Approval Gate**: Golden file updates require explicit `golden-approved` label
4. **Auto-Update Command**: `npm run test:golden:update` regenerates baselines
5. **Snapshot Testing Pattern**: Similar to Jest snapshots — update with intent

```yaml
# Example workflow step
- name: Check Golden File Changes
  run: |
    npm run test:golden:diff
    if [ -f .golden-changes.md ]; then
      gh pr comment $PR_NUMBER --body-file .golden-changes.md
    fi
```

### 3. Test Data Sensitivity

**Decision**: Use synthetic scenarios based on demo projects in `scenarios/`.

### 4. Performance Baselines — Clarified

**What is being measured:**

| Metric                     | Description                                         | Target   |
| -------------------------- | --------------------------------------------------- | -------- |
| **Agent Response Time**    | Time from prompt submission to output file creation | < 60 sec |
| **Template Validation**    | Time to validate H2 structure compliance            | < 1 sec  |
| **Bicep Build**            | Time to compile all `.bicep` files                  | < 30 sec |
| **Bicep Lint**             | Time to lint all `.bicep` files                     | < 15 sec |
| **Markdown Lint**          | Time to lint all generated `.md` files              | < 10 sec |
| **Golden File Comparison** | Time to diff against baseline outputs               | < 5 sec  |
| **Full Test Suite**        | Total time for all automated tests                  | < 30 min |

**Note**: Agent response time (60 sec) measures the **user-perceived wait time**
when interacting with an agent in VS Code. This is the time a human waits for
the agent to generate its output file. Actual agent "thinking" time varies by
model and complexity—this metric ensures acceptable UX.

---

## Summary for Architecture Assessment

**Key Constraints:**

- Budget: ~$50-100/month for Azure test resources
- Automation: ≥90% of tests must run without manual intervention
- Speed: Full test suite must complete in <30 minutes
- Coverage: All 9 agents must have functional tests

**Recommended Approach:**

1. Extend existing `validate-artifact-templates.mjs` pattern for template compliance
2. Use PowerShell for test orchestration (consistent with existing scripts)
3. Store golden files in `scenarios/*/expected-outputs/` for version control
4. Use GitHub Actions for CI/CD with environment protection for Azure tests
5. Implement phased rollout starting with template compliance and bicep validation

**Next Steps:**

- Proceed to `architect` agent for test framework architecture design
- Define detailed module structure for test utilities
- Design Azure test subscription configuration

---

_Requirements captured using the plan agent | 2026-01-22_
